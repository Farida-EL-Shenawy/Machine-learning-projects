# -*- coding: utf-8 -*-
"""Numeric-California housing-KNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eixm3-fNPZ8a0I-tTtC8i8yL5MLDse5j
"""

import sklearn
assert sklearn.__version__>="0.20"

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import PolynomialFeatures

from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV

# Download The Dataset
X,y = fetch_california_housing(return_X_y=True)

print("Shape of feature matrix: ", X.shape)
print("Shape of label vector: ", y.shape)

#20640 examples in the dataset
#each example correspnds to one house
# represented with 8 features

#Check that we have equal number of rows in feature matrix and label vector
assert (X.shape[0] == y.shape[0])

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=8)

print("Shape of training feature matrix", X_train.shape)
print("Shape of test feature matrix", X_test.shape)

assert (X_train.shape[0] == y_train.shape[0])
assert (X_test.shape[0] == y_test.shape[0])

#Preprocessing the dataset
california_housing = fetch_california_housing(as_frame=True)
california_housing.frame.hist(figsize=(12,10),bins=30,edgecolor="black")
plt.subplots_adjust(hspace=0.7,wspace=0.4)

#MODEL BUILDING

#Create pipeline with min-max scalar followed by
#KNN regressor
pipe = Pipeline([('scaler', MinMaxScaler()),
                 ('knn', KNeighborsRegressor(n_neighbors=2))])

#Fitting and transform training data
pipe.fit(X_train, y_train)

#transform test data
y_pred = pipe.predict(X_test)

#compute RMSE
error = mean_squared_error(y_test, y_pred, squared=False)
print(error)

#MODEL SELECTION AND EVALUATION
# Manual Hyperparameter tuning with cross-validation

#to store rmse values for different k
rmse_val = []

for K in range(1,31):

  pipe = Pipeline([('scaler', MinMaxScaler()),
                   ('knn', KNeighborsRegressor(n_neighbors=K))])
  #fit the model
  pipe.fit(X_train, y_train)

  #make prediction on test set
  pred = pipe.predict(X_test)

  #calculate rmse
  error = mean_squared_error(y_test,pred,squared= False)
  #store rmse values
  rmse_val.append(error)

# At the end of for loop we get a lest of RMSEs
# One for each K value

plt.figure(figsize=(10,10))

#plotting the rmse values againest K values
plt.plot(range(1, len(rmse_val)+1), rmse_val, color='green')
plt.xlabel('Different values of K', fontsize=20)
plt.ylabel('RMSE', fontsize=20, rotation=0)
plt.grid(True)

#Displaying the title
plt.title("Validation Loss vs K", fontsize=24)

plt.show()

#HPT with GridSearchCV

param_grid = {'knn__n_neighbors': list(range(1,31))}
print(param_grid)

pipe = Pipeline([('scaler', MinMaxScaler()),
                 ('knn', KNeighborsRegressor())])

#validate model with his parameters
gs = GridSearchCV(estimator = pipe,
                  param_grid=param_grid,
                  cv=10, n_jobs=-1,
                  return_train_score=True)
gs.fit(X_train, y_train)
reg_knn = gs.best_estimator_

#Printing best estimator values
print(reg_knn)

gs.best_estimator_
Pipeline(steps=[('scaler', MinMaxScaler()),
                ('knn', KNeighborsRegressor(n_neighbors=6))])

#make prediction on test set
pred = gs.best_estimator_.predict(X_test)
error = mean_squared_error(y_test,pred,squared=False)
print('RMSE value for K is:', error)

#Polynomial Features

params = {'poly__degree':list(range(1,4)),
          'knn__n_neighbors':list(range(6,12))}
print(params)

pipe = Pipeline(steps=[('poly',PolynomialFeatures()),
                       ('scaler', MinMaxScaler()),
                       ('knn', KNeighborsRegressor())])

gs = GridSearchCV(estimator=pipe,
                  param_grid=params,
                  cv=10, n_jobs=-1)

gs.fit(X_train, y_train)
reg_knn = gs.best_estimator_
print(reg_knn)

#make prediction on test set
pred = gs.best_estimator_.predict(X_test)
error = mean_squared_error(y_test, pred ,squared=False)
print('Rmse value for K is: ',error)

